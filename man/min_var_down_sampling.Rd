% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rarefying.R
\name{min_var_down_sampling}
\alias{min_var_down_sampling}
\title{Down-sampling read counts}
\usage{
min_var_down_sampling(sample.readcounts, depth = sum(sample.readcount))
}
\arguments{
\item{sample.readcounts}{matrix with readcount data.}

\item{size}{fixed number of reads in sample after down-sampling.}

\item{rngseed}{Random generator seed, for exact reproducibility.}
}
\value{
A vector of same size as the input, but with down-sampled readcounts.
}
\description{
Down-sampling read counts with a minimum variance.
}
\details{
Down-sampling (rarefying) of read counts means reducing the number of
reads in all samples to a fixed target size. This is sometimes done prior to
some downstream analyses of read count data.

Such down-sampling is typically done by sampling either with or without
replacement. The most common is with replacement, being faster. This means the
fixed number of reads are sampled with the original read count relative
frequencies as probabilities for the various outcomes. In such cases the
OTU's with very low read counts originally may come with more reads after
down-sampling.
The sampling without replacement means the actual reads are sampled, and no
OTU can end up with more reads after down-sampling. However, both procedures
introduce an extra variance in the data, especially in the more abundant OTU's.
This variance is puerly technical and has nothing to do with the biological variation.

This function implements a down-sampling that minimizes the
variance, by only sampling the few reads needed to 'correct' the expected read
count into an actual read count, as follows:

We first compute the expected read count given target \code{size}. This is
\code{E = depth * sample.readcounts/sum(sample.readcounts)}. From this we get
the base count \code{b = floor(E)}. The remainder is
\code{r = E - b}. The remaining reads
\code{depth - sum(base)} are finally distributed over
the OTU's using \code{r/sum(r)} as the probabilities. Thus, only the
(few) remaining reads will vary randomly between repeated use of this function
on the same data.
}
\author{
Lars Snipen.
}
